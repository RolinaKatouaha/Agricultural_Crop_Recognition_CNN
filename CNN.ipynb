{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhhF9Kl3KppJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wisqOKXCKt1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08123dff-8f47-47a5-fbb8-91a9c7e16c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij4ZXJVNKutN",
        "outputId": "9adc7cfe-020e-4548-9880-e6d23a731a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyheif\n",
            "  Downloading pyheif-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyheif) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->pyheif) (2.22)\n",
            "Installing collected packages: pyheif\n",
            "Successfully installed pyheif-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyheif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEZU_UtsSSCC"
      },
      "outputs": [],
      "source": [
        "# Define your dataset directory\n",
        "Agriculture_crop = '/content/drive/MyDrive/crop_images'\n",
        "\n",
        "# Define types\n",
        "types = [\n",
        "    \"jute\", \"maize\", \"rice\", \"sugarcane\", \"wheat\"\n",
        "]\n",
        "\n",
        "# Initialize lists to hold images and their labels\n",
        "Agricultureimages = []\n",
        "Agriculturelabels = []\n",
        "\n",
        "\n",
        "\n",
        "target_size = (224, 224)  # Desired size to resize images\n",
        "\n",
        "for i, AgricultureType in enumerate(types, start=1):\n",
        "    AgricultureFolder = os.path.join(Agriculture_crop, str(i))\n",
        "    for root, dirs, files in os.walk(AgricultureFolder):\n",
        "        for file_name in files:\n",
        "            img_path = os.path.join(root, file_name)\n",
        "            _, file_extension = os.path.splitext(img_path)\n",
        "            if file_extension.lower() == '.jpeg':\n",
        "            #for add photo output folder\n",
        "            #if file_extension.lower() == '.png':\n",
        "                img = Image.open(img_path)\n",
        "            elif file_extension.lower() == '.heic':\n",
        "                try:\n",
        "                    heif_file = pyheif.read(img_path)\n",
        "                    img = Image.frombytes(\n",
        "                        heif_file.mode,\n",
        "                        heif_file.size,\n",
        "                        heif_file.data,\n",
        "                        \"raw\",\n",
        "                        heif_file.mode,\n",
        "                        heif_file.stride,\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(f\"Error opening {img_path}: {e}\")\n",
        "                    continue\n",
        "            else:\n",
        "                print(f\"Unsupported file format: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            # Resize image to target size\n",
        "            img = img.resize(target_size)\n",
        "\n",
        "            # Append image and label\n",
        "            Agricultureimages.append(np.array(img))\n",
        "            Agriculturelabels.append(AgricultureType)\n",
        "\n",
        "Agricultureimages = np.array(Agricultureimages)\n",
        "Agriculturelabels = np.array(Agriculturelabels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Number of images loaded:\", len(Agricultureimages))\n",
        "print(\"Number of labels:\", len(Agriculturelabels))\n"
      ],
      "metadata": {
        "id": "j3j-j0YgXI9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7f9ea8-989c-47a6-fe98-88449f3fd9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images loaded: 804\n",
            "Number of labels: 804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CRAazcDK6CS",
        "outputId": "37041e31-7765-45af-f22b-d59f4273ed30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 894s 42s/step - loss: 441.0617 - accuracy: 0.2022 - val_loss: 1.6100 - val_accuracy: 0.1615\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 983s 47s/step - loss: 1.6092 - accuracy: 0.2208 - val_loss: 1.6088 - val_accuracy: 0.1739\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 899s 43s/step - loss: 1.6084 - accuracy: 0.2131 - val_loss: 1.6095 - val_accuracy: 0.1739\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 896s 42s/step - loss: 1.6063 - accuracy: 0.2006 - val_loss: 1.6073 - val_accuracy: 0.1739\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 891s 42s/step - loss: 1.5951 - accuracy: 0.2100 - val_loss: 1.5466 - val_accuracy: 0.2857\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 889s 43s/step - loss: 1.6943 - accuracy: 0.2006 - val_loss: 1.5976 - val_accuracy: 0.1925\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 877s 42s/step - loss: 1.5682 - accuracy: 0.2551 - val_loss: 1.5303 - val_accuracy: 0.2919\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 881s 42s/step - loss: 1.4958 - accuracy: 0.3157 - val_loss: 1.5758 - val_accuracy: 0.2050\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 869s 42s/step - loss: 1.5737 - accuracy: 0.2255 - val_loss: 1.5465 - val_accuracy: 0.2112\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 907s 43s/step - loss: 1.4491 - accuracy: 0.3826 - val_loss: 1.3438 - val_accuracy: 0.4348\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 888s 42s/step - loss: 1.1397 - accuracy: 0.5365 - val_loss: 1.0604 - val_accuracy: 0.6087\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 881s 42s/step - loss: 0.9065 - accuracy: 0.6719 - val_loss: 1.4325 - val_accuracy: 0.6087\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 890s 43s/step - loss: 0.8145 - accuracy: 0.7387 - val_loss: 1.0298 - val_accuracy: 0.6522\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 882s 42s/step - loss: 0.5319 - accuracy: 0.8258 - val_loss: 1.3191 - val_accuracy: 0.6770\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 872s 42s/step - loss: 0.5806 - accuracy: 0.8320 - val_loss: 1.1220 - val_accuracy: 0.7329\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 873s 42s/step - loss: 0.2943 - accuracy: 0.9036 - val_loss: 1.7125 - val_accuracy: 0.7453\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 839s 40s/step - loss: 0.2495 - accuracy: 0.9253 - val_loss: 1.4415 - val_accuracy: 0.7578\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 871s 42s/step - loss: 0.2669 - accuracy: 0.9362 - val_loss: 2.3292 - val_accuracy: 0.7453\n",
            "6/6 - 51s - loss: 2.3292 - accuracy: 0.7453 - 51s/epoch - 8s/step\n",
            "\n",
            "Test accuracy: 0.7453415989875793\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    Agricultureimages, Agriculturelabels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "train_labels = label_binarizer.fit_transform(train_labels)\n",
        "test_labels = label_binarizer.transform(test_labels)\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(label_binarizer.classes_), activation=\"softmax\"))\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(train_images, train_labels, epochs=100,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMAGE SIZE = 128,128\n",
        "#--------- DATASET = 201\n",
        "#1 32,64,128 -> 29\n",
        "#2 32,32,64,64 WITH DROPOT(0.25)-> 24\n",
        "#3 64,64,128,512 -> 31.70\n",
        "\n",
        "#--------- DATASET = 804\n",
        "#4 64,64,128,512 WITH DROPOT(0.25)-> 19\n",
        "#5 64,64,128,128 WITH DROPOT(0.25)-> 16\n",
        "\n",
        "# IMAGE SIZE = 224,224\n",
        "#--------- DATASET = 804\n",
        "#6 64,64,128,128 WITH DROPOT(0.25)-> 16\n",
        "#7 32,64,128 -> 16\n",
        "#new code\n",
        "#8 32,32,64,64 WITH DROPOT(0.25)-> 42.85\n",
        "#9 32,32,64,64,128,128 WITH DROPOT(0.25)->19.75"
      ],
      "metadata": {
        "id": "N3Rpg9a-31w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming 'model' is your trained Keras model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "P8h5T5IJh_sp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}